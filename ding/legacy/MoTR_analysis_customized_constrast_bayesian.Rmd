---
title: "Data Analysis for Russian MoTR Reading Data"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Thank you very much for reading this script!

We collected Russian Mouse Tracking for Reading data (MoTR) following an eye-tracking study (Fuchs et al., resubmitted) who investigated this research question using Russian: Do grammaticality effects interact with agreement type (internal vs external) or do grammaticality effects interact with lexical type (adj vs verb) instead?

* MoTR data are similar to ET data, we extracted gaze duration, go past time, total duration, regressions etc. from the x,y screen coordinates.

On the one hand, we wanted to test teh validaty of MoTR to see whether it can replicate the findings by Fuchs et al. in eye-tracking. On the other hand, we wanted to study further "Do grammaticality effects interact with agreement type (internal vs external) or do grammaticality effects interact with lexical type (adj vs verb) instead?"

We have three types of matches in Russian. Note, all the AOI words are in the same position in a sentence. The AOI word (modifying adj, predictive adk, or verb) will try to match the gender of the noun by its morpheme. When they match each other, it is grammatical, otherwise, ungrammatical:

1. modifying adj + noun  
2. predictive adj + noun 
3. verb + noun

The tricky part is that predictive adj can belong to adjective, then by looking at  1 + 2 vs 3, we can examine "do grammaticality effects interact with lexical type (adj vs verb)?"

Predictive adj can also belong to external agreement, then by looking at 1 vs 2 + 3, we can examine "do grammaticality effects interact with agreement type (internal vs external)?"

Here comes the question -- how to analyze the data (or specifically, do the contrast coding) to find the answer to the question? i.e., to know whether agreement type or lexical type modulate grammaticality. --> Yes, we followed Fuchs et al. to collect the data and we can also just follow them to analyze the data, but I don't think their data analysis was answering the research quesiton. They used sum constrast coding for everything. I feel it is not correct.

Second question -- can we do model comparison or selection as well? For example, one model encoding the interaction with agreement type, one encoding the interaction with lexical type.


```{r libraries, echo=TRUE, results='hide', warning=FALSE, message=FALSE, eval=TRUE}
shhh <- suppressPackageStartupMessages # It's a library, so shhh!

shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))
shhh(library(brms))
shhh(library(bayesplot))
shhh(library(tidyr))
shhh(library(car))
shhh(library(HDInterval))
shhh(library(gridExtra))
shhh(library(posterior))
shhh(library(readxl))
shhh(library(stringr))
shhh(library(loo))

shhh(library(coda))
shhh(library(cmdstanr))
shhh(library(rstan))
shhh(library(rstantools))

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
rstan_options(auto_write = TRUE)
theme_set(theme_bw())
options(digits=4)
options(scipen=999)
set.seed(444)

```

# Read in ET Data
```{r ET-Data, echo=TRUE, warning=FALSE, eval=TRUE}
# First read ET data because we need some linguistic annotations from it.
file_list <- list.files("./ref/Eyetracking/", pattern = "*.xlsx", full.names = TRUE)
et_raw <- file_list %>%
  lapply(read_excel) %>%
  bind_rows()

# View(et_raw)
```

# Read in MoTR Data
```{r MoTR-Data, echo=TRUE, warning=FALSE, eval=TRUE}

# The path to the data
data_path <- "./data/"
data_names <- list.files(data_path)

# Read in the data from each participant and add to the data frame
motr_df <- data.frame()
for(name in data_names){
  subj <- gsub("reader_", "", gsub("_reading_measures.csv", "", name))
  temp_df <- read.csv(paste0(data_path, "/", name)) %>% mutate(subj_id = subj)
  motr_df <- rbind(motr_df, temp_df)
} 

motr_df <- motr_df %>% mutate(word_len = nchar(word),
                              word_length = scale(word_len)[,1]) %>% 
  group_by(subj_id, item_id) %>%
  arrange(subj_id, item_id) %>%
  mutate(word_len_pre1 = lag(word_length, n = 1),
         word_len_pre2 = lag(word_length, n = 2)) %>%
  ungroup()


View(motr_df)

# Clean the data
clean_df <- motr_df %>%
  # filter(subj_id != 171) %>%   # acc = 0.8
  filter(! list %in% c(98, 99)) %>% # filter practice and filler items
  mutate(skip = ifelse(total_duration==0, 1, 0),
         FPReg = ifelse(gaze_duration==0, NA, FPReg),
         FPFix = ifelse(gaze_duration==0, NA, FPFix)) %>%
  filter(skip == 0) %>%
  
  gather(measure, value, 18:26) %>%
  mutate(tgt_zero = if_else(measure %in% c("first_duration", "gaze_duration", "go_past_time", "right_bounded_rt", "total_duration") & value == 0, F, T)) %>%
  filter(tgt_zero != F) %>%
  dplyr::select(-tgt_zero, -cond_id, -skip, -word_len) %>%
  mutate(item_id = as.factor(item_id),
         subj_id = as.factor(subj_id)) %>%
  spread(measure, value) %>%
  gather(measure, value, c("first_duration", "gaze_duration", "go_past_time", "right_bounded_rt", "total_duration")) %>%
  mutate(outlier = value > (mean(value, na.rm = TRUE) + 3 * sd(value, na.rm = TRUE))) %>%
  filter(outlier == FALSE) %>%
  dplyr::select(-outlier) %>%
  spread(measure, value) %>%
  gather(measure, value, 21:29) %>%

  mutate(cond = case_when(
    target_gender == "M" & gender_match == "Mis" & type == "stim_adj" ~ "a",
    target_gender == "M" & gender_match == "Mis" & type == "stim_verb" ~ "b",
     target_gender == "M" & gender_match == "Mis" & type == "stim_pred_adj" ~ "c",
    target_gender == "M" & gender_match == "Match" & type == "stim_adj" ~ "d",
    target_gender == "M" & gender_match == "Match" & type == "stim_verb" ~ "e",
    target_gender == "M" & gender_match == "Match" & type == "stim_pred_adj" ~ "f",
    target_gender == "F" & gender_match == "Mis" & type == "stim_adj" ~ "g",
    target_gender == "F" & gender_match == "Mis" & type == "stim_verb" ~ "h",
    target_gender == "F" & gender_match == "Mis" & type == "stim_pred_adj" ~ "i",
    target_gender == "F" & gender_match == "Match" & type == "stim_adj" ~ "j",
    target_gender == "F" & gender_match == "Match" & type == "stim_verb" ~ "k",
    target_gender == "F" & gender_match == "Match" & type == "stim_pred_adj" ~ "l",
    TRUE ~ NA_character_ # This is the default case if none of the above conditions are met
  )) %>%
  dplyr::select(-list, -part, -type_id, -orig_item_number, -case, -animacy, -response_true, -response_chosen, -correctness) #%>%
  # drop_na()

clean_df <- clean_df %>%
  mutate(word = str_replace_all(word, "\\.", "")) %>%
  rowwise() %>%
  mutate(log_freq = ifelse(word %in% et_raw$IA_LABEL, 
                           et_raw$lg_frequency[match(word, et_raw$IA_LABEL)], 
                           NA_real_)) %>%
  ungroup()

View(clean_df)

```


### RESEARCH QUESTIONS:
 1. Are RTs different in gender-match versus gender-mismatch sentences?
 ==> main effect of grammaticality (gender match or not)
 
 2. Are RTs different in Masculine versus Feminine sentence conditions?
 ==> main effect of gender of target word
 
 3. Are RTs affected by sentence type (whether different lexical categories of the agreeing element will make the processing more difficult or not)? --> ADJ(adj + pre_adj) v.s. VERB 
 ==> main effect of lexical type of sentences. 
 
 4. Are RTs affected by sentence type (whether agreeing element instantiates internal v.s. external agreement will make a difference in processing difficulty)? --> internal (modifying adjective) v.s. external (verb or predicative adjective)
 ==> main effect of syntax type of sentences.
 
 5. Does the grammaticality effect within each lexical sentence type differ from each other? --> Whether the effect of grammaticality depends on the lexical type of the sentence (ADJ? VERB?)
 ==> interaction between grammaticality and lexical sentence type
 
 6.Does the grammaticality effect within each syntax sentence type differ from each other? --> Whether the effect of grammaticality depends on the syntax type of the sentence (internal? external?)
 ==> interaction between grammaticality and syntax sentence type
 
 7. Does the (possible) difference in the sensitivity to the grammaticality manipulation of 
     Masculine versus Feminine conditions differ between lexical sentence types (ADJ v.s. VERB)?
 ==> 3-way interaction between grammaticality, gender and lexical sentence type
 
 8. Does the (possible) difference in the sensitivity to the grammaticality manipulation of 
     Masculine versus Feminine conditions differ between syntax sentence types (internal v.s. external)?
 ==> 3-way interaction between grammaticality, gender and syntax sentence type


# contrast coding
```{r factorize, echo=TRUE, eval=TRUE}
# check conditions
clean_df$cond <- factor(clean_df$cond)
summary(clean_df$cond)
```


```{r Contrasts-customized, echo=TRUE, eval=TRUE}
# This is the handmade contrasts

clean_df <- clean_df %>% 
  mutate(
    #--------------------- main effects ---------------------
    Gram = ifelse(cond %in% c('a', 'b', 'c', 'g', 'h', 'i'), 1/6, -1/6), # Main effect grammaticality 
    Gen = ifelse(cond %in% c('a','b','c','d','e', 'f'), 1/6, -1/6), # Main effect gender
    TypL = ifelse(cond %in% c('a','c','d','f', 'g', 'i', 'j', 'l'), 1/8, -1/4), # Main effect of sentence type (ap vs v)
    TypS = ifelse(cond %in% c('a', 'd', 'g', 'j'), 1/4, -1/8), # Main effect of sentence type (a vs pv)
    
    #--------------------- 2 way interection ---------------------
    # Gram_x_TypL = ifelse(cond %in% c('a', 'c', 'i'), 1/8,
    #                  ifelse(cond %in% c('d', 'f', 'l'), -1/8,
    #                    ifelse(cond %in% c('e', 'k'), 1/4, -1/4))), # Grammaticality x type (ap v)
    
    # Gram_x_TypS = ifelse(cond %in% c('e', 'f', 'k', 'l'), 1/8,
    #                   ifelse(cond %in% c('b', 'c', 'h', 'i'), -1/8,
    #                          ifelse(cond %in% c('a', 'g'), 1/4, -1/4))), # Grammaticality x type (ap v)
    
    Gram_x_TypL = ifelse(cond %in% c('a', 'c', 'g', 'i', 'e', 'k'), 1/2, -1/2), # Grammaticality x type (ap v)
    Gram_x_TypS = ifelse(cond %in% c('a', 'g', 'e', 'f', 'k', 'l'), 1/2, -1/2), # Grammaticality x type (a pv)

    Gram_TypL_M = ifelse(cond %in% c('a', 'c', 'e'), 1/2, 
                    ifelse(cond %in% c('b', 'd', 'f'), -1/2, 0)), # gram x typl(ap v)_M
    Gram_TypS_M = ifelse(cond %in% c('a', 'e', 'f'), 1/2, 
                ifelse(cond %in% c('b', 'c', 'd'), -1/2, 0)), # gram x typs(a pv)_M
    Gram_TypL_F = ifelse(cond %in% c('g', 'i', 'k'), 1/2, 
                ifelse(cond %in% c('h', 'j', 'l'), -1/2, 0)), # gram x typl(ap v)_F
    Gram_TypS_F = ifelse(cond %in% c('a', 'e', 'f'), 1/2, 
                ifelse(cond %in% c('b', 'c', 'd'), -1/2, 0)), # gram x typs(a pv)_F
    
    #--------------------- 3 way interection ---------------------
    Gram_x_Gen_x_TypL = ifelse(cond %in% c('a', 'c', 'e', 'h', 'j', 'l'), 1/2, -1/2), # gen x typ1(ap v) x gram
    Gram_x_Gen_x_TypS = ifelse(cond %in% c('a', 'e', 'f', 'h', 'i', 'j'), 1/2, -1/2), # gen x typ1(ap v) x gram
    
    #--------------------- Within grammaticality type effects ---------------------
    Typ_Mis = ifelse(cond %in% c('a', 'c', 'g', 'i'), 1/4,
              ifelse(cond %in% c('b', 'h'), -1/2, 0)),  # type_Mis
    Typ_Match = ifelse(cond %in% c('d', 'f', 'j', 'l'), 1/4,
                  ifelse(cond %in% c('e', 'k'), -1/2, 0))  # type_Match
  ) %>% spread(measure, value) %>%
  # filter(word_nr == 3)
  filter(AOI_id == "R3")
  
clean_df
```

The dependent variables are the reading measures -- "first_duration", "gaze_duration", "go_past_time", "total_duration", "FPReg", "RegIn_incl"

The predictors are the contrasts coded conditions:  Grammaiticality,  Gender,  Lexical type, Agreement type, Grammaticality_x_Lexical type,  Grammaticality_x_Agreement type,  three way interactions.

Random effects are also included.

```{r new_lmer_models, echo=TRUE, eval=FALSE, message=TRUE}
stats_df = data.frame()

measure_types = c("first_duration", "gaze_duration", "go_past_time", "total_duration", 
                  "FPReg", "RegIn_incl"
                  )

for (meas in measure_types){
  print(paste("Fitting model for:", meas))
  
  if (meas %in% c("first_duration", "gaze_duration", "go_past_time", "total_duration")){
      model <- clean_df %>% filter(!is.na(.data[[meas]]))  %>% 
        lmer(as.formula(paste("log(", meas, ") ~ Gram + Gen + TypL + TypS + Gram_x_TypL + Gram_x_TypS + Gram_x_Gen_x_TypL + Gram_x_Gen_x_TypS + 
            (1 | item_id) + (1 + Gram | subj_id)")), 
            data = ., REML = F)
      coefs <- summary(model)$coefficients
      temp_results <- data.frame(
        measure = meas,
        beta = c("b_0", "b_Gram", "b_Gen", "b_TypL", "b_TypS", 
                 "b_Gram_x_TypL", "b_Gram_x_TypS", "b_Gram_x_Gen_x_TypL", "b_Gram_x_Gen_x_TypS"),
        bval = coefs[, "Estimate"],
        pval = coefs[, "Pr(>|t|)"]
      )
  }else{
      model <- clean_df %>% filter(!is.na(.data[[meas]]))  %>% 
        glmer(as.formula(paste(meas, "~ Gram + Gram_x_TypL + Gram_x_TypS + Gram_x_Gen_x_TypL + Gram_x_Gen_x_TypS + 
            (1 | item_id) + (1 | subj_id)")), 
            data = ., family=binomial(link = "logit"))
      coefs <- summary(model)$coefficients
      temp_results <- data.frame(
        measure = meas,
        beta = c("b_0", "b_Gram", 
                 "b_Gram_x_TypL", "b_Gram_x_TypS", "b_Gram_x_Gen_x_TypL", "b_Gram_x_Gen_x_TypS"),
        bval = coefs[, "Estimate"],
        pval = coefs[, "Pr(>|z|)"]
        )
  }
    stats_df = rbind(stats_df, temp_results)
}

stats_df = stats_df %>%
  mutate(sig = if_else(pval < 0.05, "SIG", ifelse(pval < .1, ".", "")))

View(stats_df)

# the summary statistics will be stored in stats_lmer_motr.csv

# write.csv(stats_df, "./stats/stats_lmer_motr.csv", row.names = FALSE)

```

# Model comparison
```{r}
model_comparison_df = data.frame()
measure_types = c("gaze_duration", "go_past_time", "total_duration", 
                  "FPReg", "RegIn_incl")

for (meas in measure_types){
  print(paste("Compare models for:", meas))
    if (meas %in% c("gaze_duration", "go_past_time", "total_duration")){
        model_l <- clean_df %>% filter(!is.na(.data[[meas]])) %>%
        lmer(as.formula(paste("log(", meas, ") ~  Gram + Gen + TypL  + Gram_x_TypL + Gram_x_Gen_x_TypL + 
            (1 | item_id) + (1 + Gram | subj_id)")), data = ., REML = F)

        model_s <- clean_df %>% filter(!is.na(.data[["go_past_time"]]))  %>% 
        lmer(as.formula(paste("log(", meas, ") ~ Gram + Gen + TypS  + Gram_x_TypS + Gram_x_Gen_x_TypS + 
            (1 | item_id) + (1 + Gram | subj_id)")), data = ., REML = F)
    }else{
        model_l <- clean_df %>% filter(!is.na(.data[[meas]]))  %>% 
        glmer(as.formula(paste(meas, "~ Gram + Gram_x_TypL + Gram_x_Gen_x_TypL +
            (1 | item_id)")), 
            data = ., family=binomial(link = "logit"))
        model_s <- clean_df %>% filter(!is.na(.data[[meas]]))  %>% 
        glmer(as.formula(paste(meas, "~ Gram + Gram_x_TypS + Gram_x_Gen_x_TypS +
            (1 | item_id)")), 
            data = ., family=binomial(link = "logit"))
    }
  
    aic_bic_comparison <- data.frame(
      `Dependent Variable` = meas,
      `Model Type` = c("L model", "S model"),
      AIC = c(AIC(model_l), AIC(model_s)),
      BIC = c(BIC(model_l), BIC(model_s)))
    model_comparison_df = rbind(model_comparison_df, aic_bic_comparison)
}
# write.csv(model_comparison_df, "./stats/model_comparison_lmer.csv", row.names = FALSE)
```

... I also did Bayesian modeling, but I deleted them to not being distracting. The results are in the same ballpark. 

### OBSERVATIONS:

gpt, gd, td, reg: 

1. Effects of Grammaticality are always significant. --> There are main effect of grammaticality (gender match or not).
2. Effects of condTypS are significant or nearly significant. --> Very likely, there are main effect of syntactic agreement type (adj vs verb & pred_adj)

3. The significance of condTypL is always smaller than condTypS. In Bayesian, the crI of beta for TypL (diff between adj vs verb) is always larger and 0 is more to the middle of its distribution.
* If do sum contrast for each level of type, pred_adj type is significantly different from the grand mean.

4. For gd, the interaction between TypS and Gram is significant. For td and gpt, it is also near to significance (or 0 to be in the narrow tail of its distr. in Bayesian). --> external or internal agreement will affect the process of mismatches in sentence.

5. Interaction between TypL and Gram is far from significance.

6. In td, there are three way interaction between TypL & Gram & Gen. --> coincidence? 

### CONCLUSION:

1. Longer rt and more regressions in error setences.
2. Longer rt and possibly more regressions in external agreement than internal ones. --> external is more difficult.
3. Longer rt and possibly more regressions in adj than verb sentences. --> adj structure is more difficult than verb (verb is also more frequent, according to corpus analysis).
4. But rt difference between mismatch and match is bigger in internal than in external. --> internal agreement kind of amplify the processing difficulty in mismatches. Maybe because external sentences are already difficult, so when combined with errors, the rt is not that different from in correct sentence. Maybe because people have their upboundary for the times they spend on difficult sentences? --> obviously, rt(difficult_external_type + error_sentence) < rt(difficult_external_type_sentence) + rt(error_sentence)
5. 4 is not observed in adj v.s. verb scenario.


### Plot of interactions can also be tricky. I deleted the codes for plotting to not burden you with reading, but I will attach the plotted pdfs with this script.


# As showed in this script, the modeling issues I am concerned about are:
## contrast coding, 
## model selection, 
## plots of interactions of partial effects.

